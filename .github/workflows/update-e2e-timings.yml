name: Update E2E Timings

on:
  workflow_dispatch:
    inputs:
      days_back:
        description: "Number of days to look back for timing artifacts"
        type: number
        default: 7
      min_samples:
        description: "Minimum number of timing samples required per test"
        type: number
        default: 3
  push:
    branches:
      - master
      - generate-new-test-timings
    paths:
      - ".github/workflows/update-e2e-timings.yml"
  schedule:
    # Run weekly on Sundays at 6 AM UTC
    - cron: "0 6 * * 0"

jobs:
  collect-and-average-timings:
    runs-on: ubuntu-22.04
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 22

      - name: Collect recent timing artifacts
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          DAYS_BACK: ${{ inputs.days_back || 7 }}
        run: |
          echo "Searching for merged timing artifacts from the last $DAYS_BACK days..."

          # Calculate cutoff date
          CUTOFF_DATE=$(date -d "$DAYS_BACK days ago" -u +"%Y-%m-%dT%H:%M:%SZ")
          echo "Looking for artifacts created after: $CUTOFF_DATE"

          # Find all merged timing artifacts
          mkdir -p timing-artifacts
          gh api repos/${{ github.repository }}/actions/artifacts \
            --jq ".artifacts[] | select(.name | startswith(\"merged-e2e-timings-\")) | select(.created_at > \"$CUTOFF_DATE\") | select(.expired == false) | {name, created_at, archive_download_url}" \
            > timing-artifacts/artifact-list.json
            
          echo "Found artifacts:"
          cat timing-artifacts/artifact-list.json

          # Check if we have any artifacts
          TOTAL_ARTIFACTS=$(jq '. | length' timing-artifacts/artifact-list.json 2>/dev/null || echo "0")
          echo "Found $TOTAL_ARTIFACTS artifact(s) to process"
          
          if [ "$TOTAL_ARTIFACTS" -eq "0" ]; then
            echo "‚ùå No timing artifacts found in the specified time range"
            exit 1
          fi
          
          # Download each artifact
          ARTIFACT_COUNT=0
          
          # Handle both single object and array cases
          if [ "$TOTAL_ARTIFACTS" -eq "1" ]; then
            # Single artifact - read directly
            NAME=$(jq -r '.name' timing-artifacts/artifact-list.json)
            URL=$(jq -r '.archive_download_url' timing-artifacts/artifact-list.json)
            CREATED=$(jq -r '.created_at' timing-artifacts/artifact-list.json)
            
            echo "Downloading artifact: $NAME (created: $CREATED)"
            curl -L -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" "$URL" -o "timing-artifacts/${NAME}.zip"
            
            # Extract the timing file
            mkdir -p "timing-artifacts/${NAME}"
            unzip -q "timing-artifacts/${NAME}.zip" -d "timing-artifacts/${NAME}/"
            
            # Check if timing file exists
            if [ -f "timing-artifacts/${NAME}/e2e/support/timings.json" ]; then
              cp "timing-artifacts/${NAME}/e2e/support/timings.json" "timing-artifacts/${NAME}-timings.json"
              ARTIFACT_COUNT=$((ARTIFACT_COUNT + 1))
              echo "‚úì Extracted timing data from $NAME"
            else
              echo "‚ö† No timing data found in $NAME"
            fi
            
            # Cleanup extracted directory
            rm -rf "timing-artifacts/${NAME}"
            rm "timing-artifacts/${NAME}.zip"
          else
            # Multiple artifacts - iterate through array
            while read -r artifact; do
              if [ -n "$artifact" ]; then
                NAME=$(echo "$artifact" | jq -r '.name')
                URL=$(echo "$artifact" | jq -r '.archive_download_url')
                CREATED=$(echo "$artifact" | jq -r '.created_at')
                
                echo "Downloading artifact: $NAME (created: $CREATED)"
                curl -L -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" "$URL" -o "timing-artifacts/${NAME}.zip"
                
                # Extract the timing file
                mkdir -p "timing-artifacts/${NAME}"
                unzip -q "timing-artifacts/${NAME}.zip" -d "timing-artifacts/${NAME}/"
                
                # Check if timing file exists
                if [ -f "timing-artifacts/${NAME}/e2e/support/timings.json" ]; then
                  cp "timing-artifacts/${NAME}/e2e/support/timings.json" "timing-artifacts/${NAME}-timings.json"
                  ARTIFACT_COUNT=$((ARTIFACT_COUNT + 1))
                  echo "‚úì Extracted timing data from $NAME"
                else
                  echo "‚ö† No timing data found in $NAME"
                fi
                
                # Cleanup extracted directory
                rm -rf "timing-artifacts/${NAME}"
                rm "timing-artifacts/${NAME}.zip"
              fi
            done < <(jq -c '.[]' timing-artifacts/artifact-list.json)
          fi

          echo "Successfully collected $ARTIFACT_COUNT timing artifacts"
          ls -la timing-artifacts/

      - name: Average timing data
        run: |
          node -e "
          const fs = require('fs');
          const path = require('path');

          console.log('üîÑ Processing timing artifacts to calculate averages...');

          const artifactDir = 'timing-artifacts';
          const timingFiles = fs.readdirSync(artifactDir).filter(f => f.endsWith('-timings.json'));

          console.log(\`Found \${timingFiles.length} timing files:\`);
          timingFiles.forEach(f => console.log(\`  - \${f}\`));

          if (timingFiles.length === 0) {
            console.log('‚ùå No timing files found');
            process.exit(1);
          }

          // Collect all timing data
          const allTimings = {};
          let totalFiles = 0;

          timingFiles.forEach(file => {
            try {
              const content = fs.readFileSync(path.join(artifactDir, file), 'utf8');
              const data = JSON.parse(content);
              
              if (data.durations && Array.isArray(data.durations)) {
                totalFiles++;
                data.durations.forEach(item => {
                  if (item.spec && typeof item.duration === 'number') {
                    if (!allTimings[item.spec]) {
                      allTimings[item.spec] = [];
                    }
                    allTimings[item.spec].push(item.duration);
                  }
                });
              }
            } catch (error) {
              console.log(\`‚ö† Error reading \${file}: \${error.message}\`);
            }
          });

          console.log(\`\nProcessed \${totalFiles} timing files\`);
          console.log(\`Found timing data for \${Object.keys(allTimings).length} unique tests\`);

          const minSamples = parseInt(process.env.MIN_SAMPLES || '3');
          console.log(\`Minimum samples required per test: \${minSamples}\`);

          // Calculate averages
          const averagedTimings = { durations: [] };
          let includedTests = 0;
          let excludedTests = 0;

          Object.entries(allTimings).forEach(([spec, durations]) => {
            if (durations.length >= minSamples) {
              // Calculate average, excluding outliers (remove top/bottom 10% if we have enough samples)
              let sortedDurations = [...durations].sort((a, b) => a - b);
              
              if (sortedDurations.length >= 10) {
                const removeCount = Math.floor(sortedDurations.length * 0.1);
                sortedDurations = sortedDurations.slice(removeCount, -removeCount);
              }
              
              const average = sortedDurations.reduce((sum, d) => sum + d, 0) / sortedDurations.length;
              averagedTimings.durations.push({
                spec: spec,
                duration: Math.round(average)
              });
              includedTests++;
            } else {
              excludedTests++;
              console.log(\`‚ö† Excluding \${spec} (only \${durations.length} samples, need \${minSamples})\`);
            }
          });

          console.log(\`\nüìä Results:\`);
          console.log(\`  ‚úì Included tests: \${includedTests}\`);
          console.log(\`  ‚ö† Excluded tests: \${excludedTests}\`);

          // Sort by spec name for consistency
          averagedTimings.durations.sort((a, b) => a.spec.localeCompare(b.spec));

          // Write averaged timings
          fs.writeFileSync('averaged-timings.json', JSON.stringify(averagedTimings, null, 2));
          console.log('‚úÖ Averaged timings written to averaged-timings.json');
          "
        env:
          MIN_SAMPLES: ${{ inputs.min_samples || 3 }}

      - name: Compare with existing timings
        id: compare
        run: |
          echo "üîç Comparing averaged timings with current timings.json..."

          if [ ! -f "e2e/support/timings.json" ]; then
            echo "‚ö† No existing timings.json found, will create new file"
            echo "has_changes=true" >> $GITHUB_OUTPUT
            echo "changes_summary=Creating new timings.json with $(jq '.durations | length' averaged-timings.json) tests" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Use our existing comparison script
          cp averaged-timings.json e2e/support/timings-new.json
          node -e "
          const fs = require('fs');

          function loadTimingFile(filePath) {
            try {
              const content = fs.readFileSync(filePath, 'utf8');
              const data = JSON.parse(content);
              const timings = {};
              if (data.durations && Array.isArray(data.durations)) {
                data.durations.forEach(item => {
                  if (item.spec && typeof item.duration === 'number') {
                    timings[item.spec] = item.duration;
                  }
                });
              }
              return timings;
            } catch (error) {
              console.error(\`Error loading \${filePath}: \${error.message}\`);
              return {};
            }
          }

          const oldTimings = loadTimingFile('e2e/support/timings.json');
          const newTimings = loadTimingFile('e2e/support/timings-new.json');

          const oldCount = Object.keys(oldTimings).length;
          const newCount = Object.keys(newTimings).length;

          console.log(\`Comparison: \${oldCount} old tests vs \${newCount} new tests\`);

          const allSpecs = new Set([...Object.keys(oldTimings), ...Object.keys(newTimings)]);
          let significantChanges = 0;
          let totalChanges = 0;
          const threshold = 0.1; // 10% change threshold

          for (const spec of allSpecs) {
            const oldTime = oldTimings[spec];
            const newTime = newTimings[spec];
            
            if (oldTime !== newTime) {
              totalChanges++;
              if (oldTime && newTime && oldTime > 0) {
                const pctChange = Math.abs(newTime - oldTime) / oldTime;
                if (pctChange > threshold) {
                  significantChanges++;
                }
              } else {
                significantChanges++; // New or removed tests are significant
              }
            }
          }

          console.log(\`Found \${totalChanges} total changes, \${significantChanges} significant (>10%)\`);

          const hasChanges = significantChanges > 0;
          console.log(\`Has significant changes: \${hasChanges}\`);

          // Write results for GitHub Actions
          const summary = hasChanges 
            ? \`Found \${significantChanges} significant timing changes (>\${Math.round(threshold*100)}% difference) out of \${allSpecs.size} tests\`
            : 'No significant timing changes detected';
            
          fs.writeFileSync('comparison-result.txt', hasChanges ? 'true' : 'false');
          fs.writeFileSync('comparison-summary.txt', summary);
          "

          HAS_CHANGES=$(cat comparison-result.txt)
          SUMMARY=$(cat comparison-summary.txt)

          echo "has_changes=$HAS_CHANGES" >> $GITHUB_OUTPUT
          echo "changes_summary=$SUMMARY" >> $GITHUB_OUTPUT

          echo "Result: has_changes=$HAS_CHANGES"
          echo "Summary: $SUMMARY"

      - name: Create Pull Request
        if: steps.compare.outputs.has_changes == 'true'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "üìù Creating pull request with timing updates..."

          # Create a new branch
          BRANCH_NAME="update-e2e-timings-$(date +%Y%m%d-%H%M%S)"
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          git checkout -b "$BRANCH_NAME"

          # Replace the timing file
          cp averaged-timings.json e2e/support/timings.json

          # Add and commit changes
          git add e2e/support/timings.json
          git commit -m "Update E2E test timings with averaged data

          ${{ steps.compare.outputs.changes_summary }}

          Collected timing data from ${{ inputs.days_back || 7 }} days of test runs.
          Only tests with at least ${{ inputs.min_samples || 3 }} timing samples were included.

          ü§ñ Generated automatically by update-e2e-timings workflow"

          # Push branch
          git push origin "$BRANCH_NAME"

          # Create pull request
          gh pr create \
            --title "üìä Update E2E test timings with recent data" \
            --body "$(cat <<EOF
          ## Summary
          This PR updates the E2E test timing data with averaged values from recent test runs.

          **Changes:** ${{ steps.compare.outputs.changes_summary }}

          ## Details
          - üìÖ Collected data from the last **${{ inputs.days_back || 7 }} days** of test runs
          - üìä Required minimum **${{ inputs.min_samples || 3 }} samples** per test for inclusion
          - üßÆ Used average of sample times, excluding outliers for tests with 10+ samples
          - ‚ö° This will improve test parallelization and reduce overall CI time

          ## Generated automatically
          ü§ñ This PR was created automatically by the \`update-e2e-timings\` workflow.
          The timing data helps cypress-split optimize test distribution across parallel jobs.
          EOF
          )" \
            --head "$BRANCH_NAME" \
            --base master

          echo "‚úÖ Pull request created successfully"

      - name: No changes needed
        if: steps.compare.outputs.has_changes != 'true'
        run: |
          echo "‚úÖ No significant timing changes detected - no PR needed"
          echo "${{ steps.compare.outputs.changes_summary }}"
